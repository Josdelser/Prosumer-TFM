{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aaa1df2",
   "metadata": {},
   "source": [
    "# Análisis de la demanda y producción de energía en Iraq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6130a52",
   "metadata": {},
   "source": [
    "## Introducción y carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e3cbe3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13736\\2346640209.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Normalize the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mscaled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Create the data to train our model on:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josed\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    850\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 852\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    853\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josed\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfirst_pass\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josed\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\josed\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    806\u001b[0m                 \u001b[1;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m                 \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('datosFinales.csv', index_col=0, parse_dates=True)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.sort_index(inplace=True)\n",
    "# Split data into training and validation sets\n",
    "train = data.loc['2019-01-01':'2021-01-01']\n",
    "valid = data.loc['2021-01-02':]\n",
    "\n",
    "# Convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(train)\n",
    "\n",
    "# Create the data to train our model on:\n",
    "time_steps = 30\n",
    "X_train, y_train = create_dataset(scaled_data, time_steps)\n",
    "\n",
    "# Reshape it [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b964fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Análisis en época de COVID\n",
    "# Comparing data before and after the COVID period\n",
    "pre_covid = data.loc['2019-01-01':'2020-02-23']\n",
    "during_covid = data.loc['2020-02-24':'2021-01-01']\n",
    "\n",
    "# Print the average demand and production before and during COVID (This will be printed when the script is run on the local machine)\n",
    "print(\"Average demand and production before COVID:\")\n",
    "print(pre_covid[['Demanda', 'Produccion']].mean())\n",
    "\n",
    "print(\"\\nAverage demand and production during COVID:\")\n",
    "print(during_covid[['Demanda', 'Produccion']].mean())\n",
    "\n",
    "# 3. Festivos nacionales\n",
    "# Analyzing data on national holidays and training a model to identify these days based on demand and production patterns\n",
    "holidays = [\"2019-01-01\", \"2019-06-01\", \"2019-05-01\", \"2019-07-14\", \"2019-10-03\",\n",
    "            \"2020-01-01\", \"2020-06-01\", \"2020-05-01\", \"2020-07-14\", \"2020-10-03\",\n",
    "            \"2021-01-01\", \"2021-06-01\", \"2021-05-01\", \"2021-07-14\", \"2021-10-03\"]\n",
    "\n",
    "data['Holiday'] = data.index.isin(holidays).astype(int)\n",
    "\n",
    "# Define the dataset for the LSTM model to predict holidays\n",
    "X_holiday, Y_holiday = prepare_data(data[['Demanda', 'Produccion']].values, data['Holiday'].values, look_back=30)\n",
    "\n",
    "# Define and train an LSTM model to predict national holidays\n",
    "model_holiday = Sequential()\n",
    "model_holiday.add(LSTM(100, input_shape=(30, 2)))\n",
    "model_holiday.add(Dense(1, activation='sigmoid'))\n",
    "model_holiday.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model (This will be executed on the local machine)\n",
    "# model_holiday.fit(X_holiday, Y_holiday, epochs=50, batch_size=32, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 4. Shaaban vs Ramadan\n",
    "# Analyzing data during Shaaban and Ramadan periods and training a model to identify these periods\n",
    "shaaban_ramadan_dates = {\n",
    "    \"2019\": {\"Shaaban\": (\"2019-04-06\", \"2019-05-05\"), \"Ramadan\": (\"2019-05-06\", \"2019-06-04\")},\n",
    "    \"2020\": {\"Shaaban\": (\"2020-03-25\", \"2020-04-23\"), \"Ramadan\": (\"2020-04-24\", \"2020-05-23\")},\n",
    "    \"2021\": {\"Shaaban\": (\"2021-03-14\", \"2021-04-12\"), \"Ramadan\": (\"2021-04-13\", \"2021-05-12\")}\n",
    "}\n",
    "\n",
    "def period_identifier(row):\n",
    "    for year, periods in shaaban_ramadan_dates.items():\n",
    "        for period, dates in periods.items():\n",
    "            if dates[0] <= row.name <= dates[1]:\n",
    "                return period\n",
    "    return \"Other\"\n",
    "\n",
    "data['Period'] = data.apply(period_identifier, axis=1)\n",
    "\n",
    "# Convert period names to integers for model training\n",
    "period_to_int = {'Other': 0, 'Shaaban': 1, 'Ramadan': 2}\n",
    "data['Period_encoded'] = data['Period'].map(period_to_int)\n",
    "\n",
    "# Define the dataset for the LSTM model\n",
    "X_period, Y_period = prepare_data(data[['Demanda', 'Produccion']].values, data['Period_encoded'].values, look_back=30)\n",
    "\n",
    "# Define and train an LSTM model to predict Shaaban and Ramadan\n",
    "model_period = Sequential()\n",
    "model_period.add(LSTM(100, input_shape=(30, 2)))\n",
    "model_period.add(Dense(3, activation='softmax'))  # 3 classes for Other, Shaaban, and Ramadan\n",
    "model_period.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Convert Y_period to one-hot encoding\n",
    "Y_period_one_hot = pd.get_dummies(Y_period).values\n",
    "\n",
    "# Train the model (This will be executed on the local machine)\n",
    "# model_period.fit(X_period, Y_period_one_hot, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# 5. Dickey-Fuller Test\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Check if the time series is stationary using the Dickey-Fuller test\n",
    "result = adfuller(data['Demanda'])\n",
    "print(\"ADF Statistic for Demanda:\", result[0])\n",
    "print(\"p-value:\", result[1])\n",
    "print(\"Critical Values:\", result[4])\n",
    "\n",
    "result = adfuller(data['Produccion'])\n",
    "print(\"\\nADF Statistic for Produccion:\", result[0])\n",
    "print(\"p-value:\", result[1])\n",
    "print(\"Critical Values:\", result[4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3265fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 6. Modelo ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit an ARIMA model to the 'Demanda' series\n",
    "model_arima_demanda = ARIMA(data['Demanda'], order=(5,1,0))\n",
    "model_arima_demanda_fit = model_arima_demanda.fit(disp=0)\n",
    "\n",
    "# Summary of the ARIMA model for Demanda (This will be printed when the script is run on the local machine)\n",
    "print(model_arima_demanda_fit.summary())\n",
    "\n",
    "# Fit an ARIMA model to the 'Produccion' series\n",
    "model_arima_produccion = ARIMA(data['Produccion'], order=(5,1,0))\n",
    "model_arima_produccion_fit = model_arima_produccion.fit(disp=0)\n",
    "\n",
    "# Summary of the ARIMA model for Produccion (This will be printed when the script is run on the local machine)\n",
    "print(model_arima_produccion_fit.summary())\n",
    "\n",
    "# 7. LSTM for daily and monthly analysis\n",
    "# For daily analysis, we can use the same data preparation, model definition, and training steps as above\n",
    "\n",
    "# For monthly analysis, we'll first create a monthly dataset\n",
    "data_monthly = data.resample('M').mean()\n",
    "\n",
    "# Define the dataset for the LSTM model for monthly analysis\n",
    "X_monthly, Y_monthly = prepare_data(data_monthly[['Demanda', 'Produccion']].values, look_back=3)\n",
    "\n",
    "# Define and train an LSTM model for monthly analysis\n",
    "model_monthly = Sequential()\n",
    "model_monthly.add(LSTM(100, input_shape=(3, 2)))\n",
    "model_monthly.add(Dense(2))\n",
    "model_monthly.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train the model for monthly analysis (This will be executed on the local machine)\n",
    "# model_monthly.fit(X_monthly, Y_monthly, epochs=50, batch_size=32, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8e782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
